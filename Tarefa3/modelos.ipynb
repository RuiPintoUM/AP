{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Label         ID\n",
      "0  ADVERTISEMENT\\n\\nIt's not just Osama bin Laden...  Human  D1-178627\n",
      "1  Namaste Solar Inc.’s Development Strategy Case...  Human   D1-62612\n",
      "2  Revolutionary Movements and Wars of Rebellion ...  Human   D1-47706\n",
      "3  Harnett County Public Health IT Department Ess...  Human   D1-68331\n",
      "4  More innovative gear from Bastl Instruments.\\n...  Human  D1-150166\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/balanced_output.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 20:55:26.379513: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-18 20:55:26.389016: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-18 20:55:26.455395: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-18 20:55:26.499158: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742331326.550531  124621 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742331326.566227  124621 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742331326.652489  124621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742331326.652522  124621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742331326.652525  124621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742331326.652527  124621 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-18 20:55:26.665653: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df[\"Text\"])  \n",
    "sequences = tokenizer.texts_to_sequences(df[\"Text\"])\n",
    "padded_sequences = pad_sequences(sequences, padding=\"post\")\n",
    "\n",
    "df[\"Label\"] = df[\"Label\"].map({\"Human\": 0, \"AI\": 1})  # Convertendo para números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df[\"Label\"], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/miniconda3/envs/ap/lib/python3.9/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-03-18 20:55:30.788552: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2s/step - accuracy: 0.3352 - loss: nan - val_accuracy: 0.3354 - val_loss: nan\n",
      "Epoch 2/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - accuracy: 0.3168 - loss: nan - val_accuracy: 0.3354 - val_loss: nan\n",
      "Epoch 3/100\n",
      "\u001b[1m11/37\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.3031 - loss: nan"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
    "\n",
    "model_dnn = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=X_train.shape[1]),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_dnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_dnn.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "model_rnn = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=X_train.shape[1]),\n",
    "    SimpleRNN(64, return_sequences=True),\n",
    "    SimpleRNN(32),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_rnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_rnn.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "model_lstm = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=X_train.shape[1]),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_lstm.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_bert = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Pré-processar o texto\n",
    "def encode_texts(texts):\n",
    "    return tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"tf\")\n",
    "\n",
    "train_encodings = encode_texts(df[\"Text\"].tolist())\n",
    "train_labels = df[\"Label\"].values\n",
    "\n",
    "# Treinar o modelo\n",
    "model_bert.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_bert.fit(train_encodings[\"input_ids\"], train_labels, epochs=3, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_dnn = (model_dnn.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, y_pred_dnn))\n",
    "\n",
    "y_pred_rnn = (model_rnn.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, y_pred_rnn))\n",
    "\n",
    "y_pred_lstm = (model_lstm.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, y_pred_lstm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
