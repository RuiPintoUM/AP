{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "genai.configure(api_key='AIzaSyDlTl5fVv3_dJEkKlIgnQvBl1vwPpOdyXA')\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-pro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_zero_shot(text):\n",
    "    prompt = f\"Classify the following text as 'AI' or 'Human':\\n\\n{text}\\n\\nAnswer:\"\n",
    "    \n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    classification = response.text.strip().lower()\n",
    "    \n",
    "    print(f\"resposta: {response}\")\n",
    "    print(f\"classification: {classification}\")\n",
    "    \n",
    "    if 'ai' in classification:\n",
    "        return 'AI'\n",
    "    \n",
    "    elif 'human' in classification:\n",
    "        return 'Human'\n",
    "    else:\n",
    "        return 'Uncertain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.002287666779011488\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 139,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 141\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.03925103321671486\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 143,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 145\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0067071327939629555\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 159,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 161\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.014711637049913406\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 186,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 188\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0006313673220574856\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 139,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 141\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.005513740703463554\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 149,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 151\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0004992950707674026\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 178,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 180\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.004638944752514362\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 156,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 158\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -7.733865641057491e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 161,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 163\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.008351361379027367\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 174,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 176\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -5.542254075407982e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 149,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 151\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00042924610897898674\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 146,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 148\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0004938477650284767\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 158,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 160\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.012729387730360031\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 136,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 138\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0026398152112960815\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 138,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 140\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.09045364707708359\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 164,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 166\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00541774183511734\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 150,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 152\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0037087369710206985\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 151,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 153\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0012414432130753994\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 165,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 167\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0005555269308388233\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 148,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 150\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00012207945110276341\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 162,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 164\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.000984520185738802\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 150,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 152\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0003514699637889862\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 138,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 140\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0017449756851419806\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 167,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 169\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0001741193700581789\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 178,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 180\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0004841950722038746\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 167,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 169\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.000668439082801342\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 208,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 210\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -4.2743980884552e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 201,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 203\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0019875126890838146\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 170,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 172\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0025035804137587547\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 163,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 165\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "Dataframe completo com previsões:\n",
      "       ID                                               Text predicted\n",
      "0    D1-1  The cell cycle, or cell-division cycle, is the...     Human\n",
      "1    D1-2  The cell cycle is the process by which a cell ...     Human\n",
      "2    D1-3  Photons, in many atomic models in physics, are...     Human\n",
      "3    D1-4  A photon is a fundamental particle of light an...     Human\n",
      "4    D1-5  According to the theory of plate tectonics, Ea...     Human\n",
      "5    D1-6  The theory of plate tectonics explains that Ea...     Human\n",
      "6    D1-7  Thalidomide is a pharmaceutical drug, first pr...     Human\n",
      "7    D1-8  Thalidomide is a drug that was first developed...     Human\n",
      "8    D1-9  Kepler published his first two laws about plan...     Human\n",
      "9   D1-10  Kepler’s laws of planetary motion are three fu...     Human\n",
      "10  D1-11  The basic idea of biological evolution is that...     Human\n",
      "11  D1-12  Biological evolution, according to Charles Dar...     Human\n",
      "12  D1-13  Stoichiometry rests upon the very basic laws t...     Human\n",
      "13  D1-14  Stoichiometry is the branch of chemistry that ...     Human\n",
      "14  D1-15  General relativity is a theory of gravitation ...     Human\n",
      "15  D1-16  General relativity, also known as the general ...     Human\n",
      "16  D1-17  The recommended number of eggs to consume per ...     Human\n",
      "17  D1-18  The question of how many eggs one should eat p...     Human\n",
      "18  D1-19  There seems to be some merit to having a singl...     Human\n",
      "19  D1-20  No level of alcohol consumption is considered ...     Human\n",
      "20  D1-21  There are three major compounds of life: prote...     Human\n",
      "21  D1-22  Artificial sweeteners are low- or zero-calorie...     Human\n",
      "22  D1-23  Recent findings on the ecology, etiology and p...     Human\n",
      "23  D1-24  Coral reefs are among the most biodiverse and ...     Human\n",
      "24  D1-25  Although the earliest life seems to have arise...     Human\n",
      "25  D1-26  The question of how life appeared on Earth is ...     Human\n",
      "26  D1-27  We investigate the problem about the reason fo...     Human\n",
      "27  D1-28  Significant climatic oscillations on sub-centu...     Human\n",
      "28  D1-29  The COVID-19 was detected in Wuhan, central Ch...     Human\n",
      "29  D1-30  The origin of the COVID-19 pandemic, caused by...     Human\n",
      "\n",
      "Novo dataframe com ID e Label:\n",
      "       ID  Label\n",
      "0    D1-1  Human\n",
      "1    D1-2  Human\n",
      "2    D1-3  Human\n",
      "3    D1-4  Human\n",
      "4    D1-5  Human\n",
      "5    D1-6  Human\n",
      "6    D1-7  Human\n",
      "7    D1-8  Human\n",
      "8    D1-9  Human\n",
      "9   D1-10  Human\n",
      "10  D1-11  Human\n",
      "11  D1-12  Human\n",
      "12  D1-13  Human\n",
      "13  D1-14  Human\n",
      "14  D1-15  Human\n",
      "15  D1-16  Human\n",
      "16  D1-17  Human\n",
      "17  D1-18  Human\n",
      "18  D1-19  Human\n",
      "19  D1-20  Human\n",
      "20  D1-21  Human\n",
      "21  D1-22  Human\n",
      "22  D1-23  Human\n",
      "23  D1-24  Human\n",
      "24  D1-25  Human\n",
      "25  D1-26  Human\n",
      "26  D1-27  Human\n",
      "27  D1-28  Human\n",
      "28  D1-29  Human\n",
      "29  D1-30  Human\n",
      "\n",
      "O dataset foi salvo no arquivo 'LLM_dataset1.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Ler o arquivo de entrada\n",
    "df_test = pd.read_csv(\"data/dataset1_inputs.csv\", sep='\\t', on_bad_lines='skip')\n",
    "\n",
    "# Aplicar a previsão na coluna 'text'\n",
    "df_test['predicted'] = df_test['Text'].apply(classify_text_zero_shot)\n",
    "\n",
    "# Exibir o dataframe completo (opcional, para verificação)\n",
    "print(\"Dataframe completo com previsões:\")\n",
    "print(df_test)\n",
    "\n",
    "# Criar um novo dataframe com apenas 'ID' e 'Label' (usando a previsão como 'Label')\n",
    "df_output = df_test[['ID', 'predicted']].rename(columns={'predicted': 'Label'})\n",
    "\n",
    "# Exibir o novo dataframe (opcional, para verificação)\n",
    "print(\"\\nNovo dataframe com ID e Label:\")\n",
    "print(df_output)\n",
    "\n",
    "# Salvar o novo dataframe em um arquivo CSV\n",
    "df_output.to_csv('score/LLM_dataset1.csv', sep='\\t', index=False)\n",
    "print(\"\\nO dataset foi salvo no arquivo 'LLM_dataset1.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.5\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       0.00      0.00      0.00        15\n",
      "       Human       0.50      1.00      0.67        15\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.25      0.50      0.33        30\n",
      "weighted avg       0.25      0.50      0.33        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rui/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rui/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rui/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Carregar os arquivos\n",
    "preds_df = pd.read_csv(\"score/LLM_dataset1.csv\", sep='\\t', on_bad_lines='skip')\n",
    "labels_df = pd.read_csv(\"data/dataset1_outputs.csv\", sep='\\t', on_bad_lines='skip')\n",
    "\n",
    "# 2. Garantir que as colunas corretas estão sendo usadas\n",
    "# Assumindo que a coluna de previsões se chama 'Pred' e a de verdade se chama 'Label'\n",
    "y_pred = preds_df['Label']\n",
    "y_true = labels_df['Label']\n",
    "\n",
    "# 3. Comparar previsões com os rótulos reais\n",
    "print(\"Acurácia:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
