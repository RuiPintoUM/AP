{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 19:53:15.755673: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-27 19:53:16.204534: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-27 19:53:17.966677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "genai.configure(api_key='AIzaSyDlTl5fVv3_dJEkKlIgnQvBl1vwPpOdyXA')\n",
    "\n",
    "llm_model = genai.GenerativeModel('gemini-1.5-pro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_zero_shot(text):\n",
    "    prompt = f\"\"\"\n",
    "            You are an expert at distinguishing AI-generated from human-written text.\n",
    "            Read the following text carefully and classify it explicitly as either 'AI' (generated by artificial intelligence) or 'Human' (written by a real person).\n",
    "\n",
    "            Text:\n",
    "            \\\"\\\"\\\"\n",
    "            {text}\n",
    "            \\\"\\\"\\\"\n",
    "\n",
    "            Your response must strictly be either 'AI' or 'Human', with no further explanation:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    response = llm_model.generate_content(prompt)\n",
    "    print(f\"resposta: {response}\")\n",
    "    \n",
    "    classification = response.text.strip().lower()\n",
    "    \n",
    "    print(f\"classification: {classification}\")\n",
    "    \n",
    "    if 'ai' in classification:\n",
    "        return 'AI'\n",
    "    \n",
    "    elif 'human' in classification:\n",
    "        return 'Human'\n",
    "    else:\n",
    "        return 'Uncertain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_one_shot(text):\n",
    "    prompt = f\"\"\"\n",
    "            You are an expert at distinguishing AI-generated from human-written text.\n",
    "            Read the third text carefully and classify it explicitly as either 'AI' (generated by artificial intelligence) or 'Human' (written by a real person), Use the information from the first two examples:\n",
    "            \n",
    "            Text: \"Although this technique was first thought of as a way to accurately define a standard unit of current, it turned out to be more useful in the field of quantum information. Usually, qubits are stationary, making the transfer of information between them difficult. The single electrons, carried by the SAWs, can be used as so called flying qubits, able to transport information from one place to another. To realise this a single electron source is needed, as well as a receiver between which the electron can be transported. Quantum dots (QD) are typically used for these stationary electron confinements. This potential minimum is sometimes called a SAW QD. The process, as seen in the GIF on the right, is typically as follows. First SAWs are generated with an interdigital transducer with specific dimensions between the electrodes to get the favorable wavelengths. Then from the stationary QD the electron quantum tunnels to the potential minimum, or SAW QD. The SAWs transfer some kinetic energy to the electron, driving it forward.\"\n",
    "\"\n",
    "            Classification: Human\n",
    "            \n",
    "            Text: \"Many scholars argue that the full potential of plate tectonics has yet to be realized, pointing to gaps in current models and empirical validation. With recent breakthroughs, plate tectonics is becoming increasingly relevant to modern scientific challenges, such as sustainability and artificial intelligence. Despite technical difficulties, plate tectonics continues to evolve through rigorous experimentation and continuous refinement of theories. Among the many branches of science, plate tectonics stands out for its complexity and potential to reshape our understanding of the world. Plate tectonics is a field that has witnessed dramatic transformations in recent years, with scientists exploring its implications across multiple domains. While some aspects of plate tectonics remain theoretical, its real-world applications are beginning to influence innovation and policy. The ongoing development of plate tectonics has sparked discussions not only about its scientific basis but also about its ethical and societal ramifications.\"\n",
    "\"   \n",
    "            Classification: AI\n",
    "             \n",
    "            Text:\n",
    "            \\\"\\\"\\\"\n",
    "            {text}\n",
    "            \\\"\\\"\\\"\n",
    "\n",
    "            Your response must strictly be either 'AI' or 'Human', with no further explanation:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    response = llm_model.generate_content(prompt)\n",
    "    print(f\"resposta: {response}\")\n",
    "    \n",
    "    classification = response.text.strip().lower()\n",
    "    \n",
    "    print(f\"classification: {classification}\")\n",
    "    \n",
    "    if 'ai' in classification:\n",
    "        return 'AI'\n",
    "    \n",
    "    elif 'human' in classification:\n",
    "        return 'Human'\n",
    "    else:\n",
    "        return 'Uncertain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_few_shot(text):\n",
    "    prompt = f\"\"\"\n",
    "            You are an expert at distinguishing AI-generated from human-written text.\n",
    "            Read the third text carefully and classify it explicitly as either 'AI' (generated by artificial intelligence) or 'Human' (written by a real person), Use the information from the first two examples:\n",
    "            \n",
    "            Text: \"Although this technique was first thought of as a way to accurately define a standard unit of current, it turned out to be more useful in the field of quantum information. Usually, qubits are stationary, making the transfer of information between them difficult. The single electrons, carried by the SAWs, can be used as so called flying qubits, able to transport information from one place to another. To realise this a single electron source is needed, as well as a receiver between which the electron can be transported. Quantum dots (QD) are typically used for these stationary electron confinements. This potential minimum is sometimes called a SAW QD. The process, as seen in the GIF on the right, is typically as follows. First SAWs are generated with an interdigital transducer with specific dimensions between the electrodes to get the favorable wavelengths. Then from the stationary QD the electron quantum tunnels to the potential minimum, or SAW QD. The SAWs transfer some kinetic energy to the electron, driving it forward.\"\n",
    "            Classification: Human\n",
    "            \n",
    "            Text: \"Many scholars argue that the full potential of plate tectonics has yet to be realized, pointing to gaps in current models and empirical validation. With recent breakthroughs, plate tectonics is becoming increasingly relevant to modern scientific challenges, such as sustainability and artificial intelligence. Despite technical difficulties, plate tectonics continues to evolve through rigorous experimentation and continuous refinement of theories. Among the many branches of science, plate tectonics stands out for its complexity and potential to reshape our understanding of the world. Plate tectonics is a field that has witnessed dramatic transformations in recent years, with scientists exploring its implications across multiple domains. While some aspects of plate tectonics remain theoretical, its real-world applications are beginning to influence innovation and policy. The ongoing development of plate tectonics has sparked discussions not only about its scientific basis but also about its ethical and societal ramifications.\"\n",
    "            Classification: AI\n",
    "            \n",
    "            Text: \"While some aspects of chemical engineering remain theoretical, its real-world applications are beginning to influence innovation and policy. Academic interest in chemical engineering continues to grow as new tools and interdisciplinary frameworks provide fresh insights and unexpected results. The ongoing development of chemical engineering has sparked discussions not only about its scientific basis but also about its ethical and societal ramifications. Among the many branches of science, chemical engineering stands out for its complexity and potential to reshape our understanding of the world. In the study of chemical engineering, researchers continue to grapple with foundational questions that challenge long-held theories and methodologies. With recent breakthroughs, chemical engineering is becoming increasingly relevant to modern scientific challenges, such as sustainability and artificial intelligence. Despite technical difficulties, chemical engineering continues to evolve through rigorous experimentation and continuous refinement of theories. Efforts to understand chemical engineering often lead to collaborations between institutions, enabling faster progress and\"\n",
    "            Classification: AI\n",
    "            \n",
    "            Text: \"Clay chemistry is an applied subdiscipline of chemistry which studies the chemical structures, properties and reactions of or involving clays and clay minerals. It is a multidisciplinary field, involving concepts and knowledge from inorganic and structural chemistry, physical chemistry, materials chemistry, analytical chemistry, organic chemistry, mineralogy, geology and others. The study of the chemistry (and physics) of clays and clay minerals is of great academic and industrial relevance as they are among the most widely used industrial minerals, being employed as raw materials (ceramics, pottery, etc. ), adsorbents, catalysts, additives, mineral charges, medicines, building materials and others. The unique properties of clay minerals including: nanometric scale layered construction, presence of fixed and interchangeable charges, possibility of adsorbing and hosting (intercalating) molecules, ability of forming stable colloidal dispersions, possibility of tailored surface and interlayer chemical modification and others, make the study of clay chemistry a very important and extremely varied field of research.\"\n",
    "            Classification: Human\n",
    "            \n",
    "            \n",
    "             \n",
    "            Text:\n",
    "            \\\"\\\"\\\"\n",
    "            {text}\n",
    "            \\\"\\\"\\\"\n",
    "\n",
    "            Your response must strictly be either 'AI' or 'Human', with no further explanation:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    response = llm_model.generate_content(prompt)\n",
    "    print(f\"resposta: {response}\")\n",
    "    \n",
    "    classification = response.text.strip().lower()\n",
    "    \n",
    "    print(f\"classification: {classification}\")\n",
    "    \n",
    "    if 'ai' in classification:\n",
    "        return 'AI'\n",
    "    \n",
    "    elif 'human' in classification:\n",
    "        return 'Human'\n",
    "    else:\n",
    "        return 'Uncertain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def retrieve_similar_texts(query_text, dataset_texts, dataset_labels, dataset_embeddings, top_k=3):\n",
    "    query_embedding = embedding_model.encode([query_text])\n",
    "    similarities = cosine_similarity(query_embedding, dataset_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    retrieved = [(dataset_texts[i], dataset_labels[i]) for i in top_indices]\n",
    "    return retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_orag_prompt(retrieved_examples, query_text):\n",
    "    examples_formatted = \"\\n\".join(\n",
    "        [f'{idx+1}. \"{text}\" — Classification: {label}' for idx, (text, label) in enumerate(retrieved_examples)]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "            You are an expert at distinguishing AI-generated from human-written text. \n",
    "            Carefully analyze the provided similar examples retrieved specifically for this task, then classify the given text explicitly as \"AI\" or \"Human\".\n",
    "\n",
    "            Retrieved examples:\n",
    "            {examples_formatted}\n",
    "\n",
    "            Text to classify:\n",
    "            \"{query_text}\"\n",
    "\n",
    "            Your response must strictly be either \"AI\" or \"Human\", without any additional explanation:\n",
    "            \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_orag(query_text, dataset_texts, dataset_labels, dataset_embeddings, top_k=3):\n",
    "    # Recuperar exemplos semelhantes dinamicamente\n",
    "    retrieved_examples = retrieve_similar_texts(query_text, dataset_texts, dataset_labels, dataset_embeddings, top_k)\n",
    "\n",
    "    # Construir o prompt ORAG\n",
    "    prompt = build_orag_prompt(retrieved_examples, query_text)\n",
    "\n",
    "    response = llm_model.generate_content(prompt)\n",
    "    classification = response.text.strip().lower()\n",
    "\n",
    "    if 'ai' in classification:\n",
    "        return 'AI'\n",
    "    elif 'human' in classification:\n",
    "        return 'Human'\n",
    "    else:\n",
    "        return 'Uncertain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0006985823274590075\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 596,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 598\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -1.1443305993452668e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 615,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 617\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.001998013351112604\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 642,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 644\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -8.344376283275778e-07\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 622,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 624\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -1.8119571905117482e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 611,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 613\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.12594428658485413\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 639,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 641\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00041966704884544015\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 628,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 630\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0030669549014419317\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 623,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 625\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.001107497257180512\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 626,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 628\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0005684577627107501\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 620,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 622\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -4.0945542423287407e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 623,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 625\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0004100766673218459\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 619,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 621\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00022358304704539478\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 654,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 656\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -9.75521033979021e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 628,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 630\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -4.124342740396969e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 628,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 630\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0001332011743215844\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 614,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 616\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -6.400999700417742e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 631,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 633\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0001502952363807708\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 641,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 643\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00015428617189172655\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 642,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 644\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0004599343810696155\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 630,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 632\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00049736094661057\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 624,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 626\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -5.2865540055790916e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 614,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 616\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00020945825963281095\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 636,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 638\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00131865288130939\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 619,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 621\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -9.552575647830963e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 609,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 611\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0002554026432335377\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 609,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 611\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.000292623823042959\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 612,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 614\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00030638129101134837\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 640,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 642\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0002494479122105986\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 644,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 646\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00018210738198831677\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 619,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 621\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -4.2792747990461066e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 634,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 636\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -9.165232040686533e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 626,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 628\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -2.8132944862591103e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 647,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 649\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -5.155399048817344e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 624,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 626\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -5.507151217898354e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 649,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 651\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -2.598626451799646e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 628,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 630\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0001378505112370476\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 619,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 621\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -3.3141735912067816e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 628,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 630\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -4.011143755633384e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 632,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 634\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -5.346171383280307e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 634,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 636\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0003144223301205784\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 632,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 634\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00022727840405423194\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 686,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 688\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0020418076310306787\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 626,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 628\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -4.124342740396969e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 639,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 641\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -9.362654236610979e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 619,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 621\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -4.154378257226199e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 644,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 646\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00021553707483690232\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 621,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 623\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -3.7016441638115793e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 612,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 614\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -2.276727718708571e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 613,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 615\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0001410774711985141\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 623,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 625\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -4.7860750783002004e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 614,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 616\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00020582300203386694\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 661,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 663\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00034467712976038456\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 655,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 657\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0008337993640452623\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 628,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 630\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -2.2053013708500657e-06\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 610,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 612\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -2.3601707653142512e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 631,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 633\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -1.633269312151242e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 617,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 619\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -2.264806244056672e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 615,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 617\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00035015682806260884\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 623,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 625\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -2.8967862817808054e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 609,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 611\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -5.76355196244549e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 627,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 629\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.00043658920913003385\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 624,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 626\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.006258999463170767\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 619,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 621\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -2.544955896155443e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 613,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 615\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -2.2290456399787217e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 603,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 605\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0004410511755850166\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 621,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 623\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0007520373328588903\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 607,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 609\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -2.1098579964018427e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 611,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 613\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -9.537068308418384e-07\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 614,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 616\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0038303204346448183\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 616,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 618\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0004856602754443884\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 619,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 621\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -3.8444944948423654e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 621,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 623\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0006169785046949983\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 610,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 612\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.021512510254979134\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 623,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 625\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -9.53790731728077e-07\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 619,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 621\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -9.834448974288534e-06\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 638,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 640\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.08988358825445175\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 632,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 634\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0001224814186571166\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 617,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 619\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -4.648917638405692e-06\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 607,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 609\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -2.890825089707505e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 626,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 628\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.030994834378361702\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 604,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 606\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.011626841500401497\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 609,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 611\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -7.032329449430108e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 627,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 629\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.08014370501041412\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 621,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 623\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -4.798009467776865e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 665,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 667\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -4.64903996544308e-06\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 623,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 625\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -1.6689999029040337e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 643,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 645\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.19344839453697205\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 639,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 641\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -1.9670656001835596e-06\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 606,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 608\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.10071887075901031\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 626,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 628\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -7.74825707594573e-07\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 612,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 614\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -1.8536573406890966e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 614,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 616\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -8.73020981089212e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 646,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 648\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.5684525370597839\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 622,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 624\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -5.602553937933408e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 611,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 613\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0005206474452279508\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 611,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 613\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: ai\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -9.487017814535648e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 625,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 627\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -6.490339728770778e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 615,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 617\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -6.56793054076843e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 623,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 625\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "resposta: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Human\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -1.6748246707720682e-05\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 625,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 627\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-pro-002\"\n",
      "    }),\n",
      ")\n",
      "classification: human\n",
      "Dataframe completo com previsões:\n",
      "       ID                                               Text predicted\n",
      "0    D3-1  String theory is a broad and varied subject th...     Human\n",
      "1    D3-2  String theory is a theoretical framework in ph...        AI\n",
      "2    D3-3  String theory proposes that the fundamental bu...     Human\n",
      "3    D3-4  I think string theory explains only the 3rd di...     Human\n",
      "4    D3-5  With all this said, one should keep in mind th...     Human\n",
      "..    ...                                                ...       ...\n",
      "95  D2-94  Synthetic biology is an interdisciplinary fiel...        AI\n",
      "96  D2-96  Though a part of the continent of North Americ...     Human\n",
      "97  D2-97  There has been a steady increase in the number...     Human\n",
      "98  D2-98  Plasticizers like phthalates were thought to b...     Human\n",
      "99  D2-99  The main causes of lung cancer are multifacete...     Human\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "\n",
      "Novo dataframe com ID e Label:\n",
      "       ID  Label\n",
      "0    D3-1  Human\n",
      "1    D3-2     AI\n",
      "2    D3-3  Human\n",
      "3    D3-4  Human\n",
      "4    D3-5  Human\n",
      "..    ...    ...\n",
      "95  D2-94     AI\n",
      "96  D2-96  Human\n",
      "97  D2-97  Human\n",
      "98  D2-98  Human\n",
      "99  D2-99  Human\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "O dataset foi salvo no arquivo 'LLM_dataset1.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Ler o arquivo de entrada\n",
    "df_test = pd.read_csv(\"data/dataset3_inputs.csv\", sep=';', on_bad_lines='skip')\n",
    "\n",
    "# Aplicar a previsão na coluna 'text'\n",
    "df_test['predicted'] = df_test['Text'].apply(classify_text_one_shot)\n",
    "\n",
    "# Exibir o dataframe completo (opcional, para verificação)\n",
    "print(\"Dataframe completo com previsões:\")\n",
    "print(df_test)\n",
    "\n",
    "# Criar um novo dataframe com apenas 'ID' e 'Label' (usando a previsão como 'Label')\n",
    "df_output = df_test[['ID', 'predicted']].rename(columns={'predicted': 'Label'})\n",
    "\n",
    "# Exibir o novo dataframe (opcional, para verificação)\n",
    "print(\"\\nNovo dataframe com ID e Label:\")\n",
    "print(df_output)\n",
    "\n",
    "# Salvar o novo dataframe em um arquivo CSV\n",
    "df_output.to_csv('score/LLM_dataset3.csv', sep='\\t', index=False)\n",
    "print(\"\\nO dataset foi salvo no arquivo 'LLM_dataset1.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Label\n",
      "0  D1-1  Human\n",
      "1  D1-2  Human\n",
      "2  D1-3  Human\n",
      "3  D1-4     AI\n",
      "4  D1-5  Human\n"
     ]
    }
   ],
   "source": [
    "# Carregar seu dataset etiquetado\n",
    "df_train = pd.read_csv(\"data/dataset_final.csv\", sep=',')\n",
    "dataset_texts = df_train[\"Text\"].tolist()\n",
    "dataset_labels = df_train[\"Label\"].tolist()\n",
    "\n",
    "# Gerar embeddings para seu dataset (faça apenas uma vez, salve se necessário)\n",
    "dataset_embeddings = embedding_model.encode(dataset_texts)\n",
    "\n",
    "# Carregar dataset que pretende classificar\n",
    "df_test = pd.read_csv(\"data/dataset1_inputs.csv\", sep='\\t')\n",
    "\n",
    "# Aplicar ORAG para classificação dos textos\n",
    "df_test['Label'] = df_test['Text'].apply(\n",
    "    lambda x: classify_text_orag(x, dataset_texts, dataset_labels, dataset_embeddings)\n",
    ")\n",
    "\n",
    "# Salvar resultados classificados\n",
    "df_test[['ID', 'Label']].to_csv(\"LLM_dataset1.csv\", sep='\\t', index=False)\n",
    "\n",
    "# Visualizar resultado\n",
    "print(df_test[['ID', 'Label']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       1.00      0.40      0.57        15\n",
      "       Human       0.62      1.00      0.77        15\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.81      0.70      0.67        30\n",
      "weighted avg       0.81      0.70      0.67        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Carregar os arquivos\n",
    "preds_df = pd.read_csv(\"score/LLM_dataset1.csv\", sep='\\t', on_bad_lines='skip')\n",
    "labels_df = pd.read_csv(\"data/dataset1_outputs.csv\", sep='\\t', on_bad_lines='skip')\n",
    "\n",
    "# 2. Garantir que as colunas corretas estão sendo usadas\n",
    "# Assumindo que a coluna de previsões se chama 'Pred' e a de verdade se chama 'Label'\n",
    "y_pred = preds_df['Label']\n",
    "y_true = labels_df['Label']\n",
    "\n",
    "# 3. Comparar previsões com os rótulos reais\n",
    "print(\"accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
